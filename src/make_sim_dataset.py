import genesis as gs
import numpy as np
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from env.genesis_env import GenesisEnv
from env.tasks.test import joints_name
from lerobot.common.datasets.lerobot_dataset import LeRobotDataset
import os
import numpy as np
from PIL import Image

task_description = {
    "test": "Pick up a red cube and place it in a box.",
}
    
def expert_policy(env, stage):
    task = env._env
    cube_pos = task.cubeA.get_pos().cpu().numpy()
    box_pos = task.box.get_pos().cpu().numpy()
    # motors_dof = task.motors_dof
    # fingers_dof = task.fingers_dof
    finder_pos = -0.02  # tighter grip
    quat = np.array([0, 1, 0, 0]) # Changed from [[0, 1, 0, 0]] to [0, 1, 0, 0]
    eef = task.eef

    # === Stage definitions ===
    if stage == "hover":
        target_pos = cube_pos + np.array([0.0, 0.0, 0.2])  # hover safely
        grip = np.array([0.04, 0.04])  # open
    elif stage == "stabilize":
        target_pos = cube_pos + np.array([0.0, 0.0, 0.1])
        grip = np.array([0.04, 0.04])  # still open
    elif stage == "grasp":
        target_pos = cube_pos + np.array([0.0, 0.0, 0.1])  # lower slightly
        grip = np.array([finder_pos, finder_pos])  # close grip
    elif stage == "lift":
        target_pos = np.array([cube_pos[0], cube_pos[1], 0.25])
        grip = np.array([finder_pos, finder_pos])  # keep closed
    elif stage == "to_box":
        target_pos = box_pos + np.array([0.0, 0.0, 0.25])
        grip = np.array([finder_pos, finder_pos])
    elif stage == "stabilize_box":
        target_pos = box_pos + np.array([0.0, 0.0, 0.25])
        grip = np.array([finder_pos, finder_pos])
    elif stage == "release":
        target_pos = box_pos + np.array([0.0, 0.0, 0.25])
        grip = np.array([0.04, 0.04])
    else:
        raise ValueError(f"Unknown stage: {stage}")
    # Use IK to compute joint positions for the arm
    qpos = task.franka.inverse_kinematics(
        link=eef,
        pos=target_pos,
        quat=quat,
    ).cpu().numpy()
    qpos_arm = qpos[:-2]
    action = np.concatenate([qpos_arm, grip]) # Shape (9)
    return action.astype(np.float32)

def initialize_dataset(task, height, width):
    # Initialize dataset
    dict_idx = 0
    dataset_path = f"datasets/{task}_{dict_idx}"
    while os.path.exists(f"datasets/{task}_{dict_idx}"):
        dict_idx += 1
        dataset_path = f"datasets/{task}_{dict_idx}"
    lerobot_dataset = LeRobotDataset.create(
        repo_id=None,
        fps=30,
        root=dataset_path,
        robot_type="franka",
        use_videos=True,
        features={
            "observation.state": {"dtype": "float32", "shape": (9,), "names": joints_name},
            "action": {"dtype": "float32", "shape": (9,), "names": joints_name},
            "observation.images.front": {"dtype": "video", "shape": (height, width, 3), "names": ("height", "width", "channels")},
            "observation.images.side": {"dtype": "video", "shape": (height, width, 3), "names": ("height", "width", "channels")},
        },
    )
    return lerobot_dataset

def main(task, task_description, stage_dict, observation_height=480, observation_width=640, episode_num=1, show_viewer=False):
    gs.init(backend=gs.cpu, precision="32", debug=False, logging_level="WARNING") # cpuã®æ–¹ãŒæ—©ã„ï¼Ÿ
    env = None
    dataset = initialize_dataset(task, observation_height, observation_width)
    ep = 0
    while ep < episode_num:
        print(f"\nğŸ¬ Starting episode {ep+1}")
        if ep % 10 == 0:
            # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’é¿ã‘ã‚‹ãŸã‚ã«ã€10ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã”ã¨ã«ç’°å¢ƒã‚’ãƒªã‚»ãƒƒãƒˆ
            if env is not None:
                env.close()
            env = GenesisEnv(task=task, observation_height=observation_height, observation_width=observation_width, show_viewer=show_viewer)
        env.reset()
        states, images_front, images_side, actions = [], [], [], []
        reward_greater_than_zero = False
        for stage in stage_dict.keys():
            print(f"  Stage: {stage}")
            for t in range(stage_dict[stage]):
                action = expert_policy(env, stage)
                obs, reward, _, _, _ = env.step(action)
                states.append(obs["agent_pos"])
                images_front.append(obs["observation.images.front"])
                images_side.append(obs["observation.images.side"])
                actions.append(action)
                if reward > 0:
                    reward_greater_than_zero = True
        # ãƒ‡ãƒãƒƒã‚°ç”¨
        # env.save_video(file_name=f"video", fps=30)

        if not reward_greater_than_zero:
            print(f"ğŸš« Skipping episode {ep+1} â€” reward was always 0")
            continue
        print(f"âœ… Saving episode {ep+1}")
        ep += 1

        for i in range(len(states)):
            image_front = images_front[i]
            if isinstance(image_front, Image.Image):
                image_front = np.array(image_front)
            image_side = images_side[i]
            if isinstance(image_side, Image.Image):
                image_side = np.array(image_side)

            dataset.add_frame(
                {
                    "observation.state": states[i].astype(np.float32),
                    "action": actions[i].astype(np.float32),
                    "observation.images.front": image_front,
                    "observation.images.side": image_side,
                },
                task_description[task],
            )
        dataset.save_episode()
    env.close()

if __name__ == "__main__":
    task = "test" # [test]
    stage_dict = { # 350
        "hover": 100, # cubeã®ä¸Šã«æ‰‹ã‚’æŒã£ã¦ã„ã
        "stabilize": 40, # cubeã®ä¸Šã§æ‰‹ã‚’å®‰å®šã•ã›ã‚‹
        "grasp": 20, # cubeã‚’æ´ã‚€
        "lift": 50, # cubeã‚’æŒã¡ä¸Šã’ã‚‹
        "to_box": 60, # cubeã‚’ç®±ã®ä¸Šã«æŒã£ã¦ã„ã
        "stabilize_box": 20, # cubeã‚’ç®±ã®ä¸Šã§å®‰å®šã•ã›ã‚‹
        "release": 60, # cubeã‚’é›¢ã™
    }
    main(task, task_description, stage_dict=stage_dict, observation_height=480, observation_width=640, episode_num=100, show_viewer=False)